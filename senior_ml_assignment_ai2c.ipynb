{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Machine Learning Assignment: Predicting Extreme Events in Apple Stock Prices\n",
    "\n",
    "## Objective\n",
    "The goal of this assignment is to predict **extreme events** in Apple stock prices using machine learning techniques. An **extreme event** is defined as a **daily price movement exceeding 2%** in either direction (positive or negative) compared to the previous day.\n",
    "\n",
    "You are required to:\n",
    "1. Build a **Random Forest** classifier and a **Temporal Convolutional Neural Network (TCNN)** to predict extreme events using the previous 10 days of stock data.\n",
    "2. Evaluate the models on test data and analyze their performance.\n",
    "3. Suggest and implement improvements on the TCNN to enhance the models' performance.\n",
    "\n",
    "---\n",
    "\n",
    "### Assignment Tasks\n",
    "1. **Data Preprocessing**: Load, preprocess, and engineer features from historical stock data.\n",
    "2. **Random Forest Model**: Build and train a Random Forest classifier for extreme event prediction.\n",
    "3. **Temporal CNN Model**: Build and train a Temporal CNN model for extreme event prediction.\n",
    "4. **Model Evaluation**: Compare the performance of the models.\n",
    "5. **Improvement Task**: Suggest and implement approaches to improve the performance of the TCNN model.\n",
    "\n",
    "---\n",
    "\n",
    "## Task 1: Data Preprocessing\n",
    "\n",
    "### Step 1.1: Load the Data\n",
    "Download **Apple stock data** (from January 2015 to January 2024) from [Yahoo Finance](https://finance.yahoo.com/) or use a similar source. The dataset should include the following columns:\n",
    "- `Open`\n",
    "- `High`\n",
    "- `Low`\n",
    "- `Close`\n",
    "- `Volume`\n",
    "- `Adj Close` (Adjusted Close)\n",
    "\n",
    "Load the dataset into a pandas DataFrame and inspect the first few rows to verify the data.\n",
    "\n",
    "### Step 1.2: Calculate Daily Returns\n",
    "Calculate the daily percentage return for Apple stock based on the adjusted closing price. This can be computed using:\n",
    "- `Daily_Return = (Adj Close_t - Adj Close_t-1) / Adj Close_t-1 * 100`\n",
    "\n",
    "Ensure that missing values in the dataset (due to holidays or weekends) are handled appropriately.\n",
    "\n",
    "### Step 1.3: Define Extreme Events\n",
    "Define an **extreme event** as any day where the percentage change in the adjusted close price exceeds **±2%**. Create a binary column `Extreme_Event` with the following logic:\n",
    "- `1` if the daily return is greater than 2% or less than -2% (extreme event).\n",
    "- `0` if the daily return is between -2% and 2% (no event).\n",
    "\n",
    "Next, shift the target variable `Extreme_Event` by one day so that the model is trained to predict if an extreme event occurs **tomorrow** based on today's data.\n",
    "\n",
    "### Step 1.4: Split Data into Features and Target\n",
    "Extract the following columns as features for the model:\n",
    "- `Open`\n",
    "- `High`\n",
    "- `Low`\n",
    "- `Close`\n",
    "- `Volume`\n",
    "- `Daily_Return`\n",
    "\n",
    "The target variable will be the `Extreme_Event` column created earlier.\n",
    "\n",
    "Split the data into **70% training**, **15% validation**, and **15% test** sets. Make sure to split the data in sequence to preserve the time-series nature of the stock data and avoid data leackage.\n",
    "\n",
    "---\n",
    "\n",
    "## Task 2: Random Forest Model\n",
    "\n",
    "### Step 2.1: Model Training\n",
    "You are required to build a **Random Forest Classifier** to predict extreme events using 10 days of historical stock data. You can use **scikit-learn** for this task.\n",
    "\n",
    "- Train the Random Forest classifier using the training data (features from the past 10 days).\n",
    "- Evaluate the model on the validation set to tune hyperparameters if necessary.\n",
    "\n",
    "### Step 2.2: Model Evaluation\n",
    "Evaluate the performance of the **Random Forest** model on the **test set**. Report the following metrics:\n",
    "- **Confusion Matrix**\n",
    "- **Accuracy**\n",
    "- **Precision, Recall, F1-Score**\n",
    "\n",
    "Explain whether the model is performing well in predicting extreme events and if there are any signs of overfitting or underfitting.\n",
    "\n",
    "---\n",
    "\n",
    "## Task 3: Temporal CNN Model\n",
    "\n",
    "### Step 3.1: Input Preparation\n",
    "For the **Temporal Convolutional Neural Network (TCNN)**, the input will consist of **sequences of 10 days** of stock data (features). The model will predict whether an extreme event will occur on the **next day** based on these sequences.\n",
    "\n",
    "Prepare the data as follows:\n",
    "- Convert the input data into sequences of 10 days, where each sequence is used to predict the target label for the next day.\n",
    "- Ensure the input shape is suitable for a CNN: `[batch_size, num_features, sequence_length]`.\n",
    "\n",
    "### Step 3.2: Model Architecture\n",
    "Build a **Temporal CNN** model using PyTorch, with the following specifications:\n",
    "- Two **1D Convolutional layers** to extract temporal features across the 10-day window.\n",
    "- **ReLU** activations after each convolution layer.\n",
    "- A fully connected **Dense layer** after flattening the features from the CNN layers.\n",
    "- Use **Softmax** for the output layer to predict the probability of the two classes (extreme event vs no event).\n",
    "\n",
    "### Step 3.3: Model Training\n",
    "Train the **Temporal CNN** using the **Adam optimizer** and **Cross-Entropy Loss**. Monitor the performance on the validation set at the end of each epoch.\n",
    "\n",
    "Ensure the training process handles potential issues like overfitting by using techniques such as:\n",
    "- **Early stopping**\n",
    "- **Dropout** layers\n",
    "\n",
    "### Step 3.4: Model Evaluation\n",
    "After training, evaluate the performance of the **Temporal CNN** model on the **test set**. Report the same metrics as for the Random Forest model:\n",
    "- **Confusion Matrix**\n",
    "- **Accuracy**\n",
    "- **Precision, Recall, F1-Score**\n",
    "\n",
    "---\n",
    "\n",
    "## Task 4: Model Comparison\n",
    "\n",
    "### Step 4.1: Compare the Models\n",
    "Compare the performance of the **Random Forest** and **Temporal CNN** models based on the evaluation metrics. Address the following questions:\n",
    "- Which model performs better for predicting extreme events?\n",
    "- Which metric or metrics are more relevant for evaluating the performance of the methods?\n",
    "- Why is forecasting of such events a challenging task? Name three reasons.\n",
    "- How well do the models handle class imbalance (extreme events vs no extreme events)?\n",
    "- Can you assess the predictability of the models based on their performance? Given the potentially low performance, would you say the models demonstrate predictive ability for extreme events in stock prices? Please explain your reasoning.\n",
    "\n",
    "---\n",
    "\n",
    "## Task 5: Improvement Task\n",
    "\n",
    "### Step 5.1: Performance Improvement\n",
    "The performance of the models is relatively low.\n",
    "Propose and implement improvements to enhance the performance of the **Temporal CNN** model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Instructions\n",
    "\n",
    "Your submission should be organized in a folder containing all necessary files to ensure **reproducibility** and clear documentation of your work. The folder should be structured as follows:\n",
    "\n",
    "### **Folder Structure**:\n",
    "\n",
    "```\n",
    "submission/\n",
    "│\n",
    "├── src/                 # Directory containing all Python executable scripts\n",
    "│   ├── data_processing.py\n",
    "│   ├── random_forest.py\n",
    "│   ├── temporal_cnn.py\n",
    "│   ├── model_evaluation.py\n",
    "│   └── improvement.py\n",
    "│\n",
    "├── README.md            # Detailed instructions on how to run the code\n",
    "│\n",
    "├── pyproject.toml       # Poetry configuration file for dependency management\n",
    "├── poetry.lock          # Poetry lock file for reproducibility\n",
    "│\n",
    "├── report.pdf           # A detailed report including model performance and analysis\n",
    "│\n",
    "└── data/                # Directory for any required dataset or files\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Submission Components**:\n",
    "\n",
    "1. **Python Executables** (`src/`):\n",
    "   - The `src/` folder should contain **Python scripts** for each major task:\n",
    "     - `data_processing.py`: Script to load, preprocess, and engineer features from the stock data.\n",
    "     - `random_forest.py`: Script to build and train the Random Forest model.\n",
    "     - `temporal_cnn.py`: Script to build and train the Temporal CNN model.\n",
    "     - `model_evaluation.py`: Script to evaluate the models and generate performance metrics.\n",
    "     - `improvement.py`: Script for any additional improvements made to enhance model performance.\n",
    "   Each script should be modular and runnable as standalone or as part of an automated pipeline.\n",
    "\n",
    "2. **README.md**:\n",
    "   - Include a **comprehensive README** file that provides step-by-step instructions on how to set up the environment and run the code.\n",
    "   - Clearly explain how to run each script in the `src/` folder, how to reproduce the results, and what dependencies are required.\n",
    "   - The README should also specify any additional configuration or dataset download steps.\n",
    "\n",
    "3. **Dependency Management**:\n",
    "   - Use **Poetry** (or a similar dependency management tool) to handle all necessary dependencies.\n",
    "     - Include the `pyproject.toml` file that defines the environment.\n",
    "     - Include the `poetry.lock` file to ensure full reproducibility of the environment.\n",
    "   - Ensure that all external libraries, dependencies, and versions are captured in these files to allow for seamless recreation of the development environment.\n",
    "\n",
    "4. **Report (report.pdf)**:\n",
    "   - Submit a **detailed report** in PDF format that includes:\n",
    "     - Performance metrics (confusion matrix, precision, recall, F1-score) for both the Random Forest and Temporal CNN models.\n",
    "     - A discussion of the results, model predictability, and potential areas for improvement.\n",
    "     - An explanation of the improvement implemented in `improvement.py` and its impact on model performance.\n",
    "\n",
    "5. **Reproducibility**:\n",
    "   - The submission must be fully **reproducible**. Anyone with access to the submission should be able to:\n",
    "     1. Set up the environment using the provided `pyproject.toml` and `poetry.lock`.\n",
    "     2. Run the provided Python scripts and obtain the same results as presented in your report.\n",
    "\n",
    "## **Important Notes**:\n",
    "- Don't expect to completely solve the assignment and achieve very high performance scores, as forecasting stock price movements is a very challenging and difficult task. \n",
    "- The **accuracy of the results** is important, but equal emphasis will be placed on the clarity of your code, your ability to handle dependencies, and your documentation.\n",
    "- **Reproducibility** is critical, so please ensure that all dependencies and code required to generate your results are included in the submission.\n",
    "- While achieving good results is important, the emphasis of this assignment is on **critical and creative thinking**. A clear, thoughtful analysis with creative ideas will be valued over simply producing a high-accuracy model. In this respect, **Task 5** is the most important one.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
